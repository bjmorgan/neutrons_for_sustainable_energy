# Beyond molecular dynamics

In Part I, we covered methods for calculating E(r) — classical potentials, DFT, and machine-learned interatomic potentials. In Part II, we turned to what we do with that ability: finding stable structures through geometry optimisation, characterising vibrations through phonon calculations, and simulating atomic motion through molecular dynamics.

MD samples configurations by following the physical dynamics of the system. At finite temperature, atoms have kinetic energy and explore the potential energy surface. For fast processes — ionic diffusion in superionic conductors, thermal vibrations — MD captures the relevant configurations.

But some configurational questions involve rearrangements that are far too slow for MD. Consider cation ordering in a mixed-metal oxide, or site occupancies in an alloy. The atoms can, in principle, rearrange — but the mechanisms are slow, involving vacancy diffusion or other activated processes that happen on timescales of seconds to hours, not nanoseconds. MD will never visit these configurations; the simulation is trapped in whatever arrangement it started with.

Monte Carlo sampling takes a different approach. Rather than following dynamics, we propose configurational changes directly and accept or reject them based on energetics. This lets us sample configurations that MD cannot reach.

# Monte Carlo sampling

## The goal: ensemble averages

Statistical mechanics tells us that macroscopic properties are ensemble averages. The expectation value of a property A in the canonical ensemble is:

$$\langle A \rangle = \sum_i A_i P_i = \frac{1}{Z} \sum_i A_i \exp(-E_i / k_B T)$$

where the sum runs over all microstates i, E<sub>i</sub> is the energy of state i, and Z is the partition function:

$$Z = \sum_i \exp(-E_i / k_B T)$$

In principle, this is straightforward: enumerate all states, calculate their energies and properties, weight by Boltzmann factors, sum. In practice, the number of states is astronomically large. For configurational disorder on N sites with two possible occupants per site, there are 2<sup>N</sup> configurations. Even for modest N, explicit enumeration is impossible.

## Why not sample uniformly?

One idea: sample configurations randomly and weight by their Boltzmann factors. The problem is that uniform sampling is inefficient. Most randomly chosen configurations have high energy and negligible Boltzmann weight — we waste effort sampling configurations that contribute almost nothing to the average.

The solution is importance sampling: sample configurations in proportion to their Boltzmann weights. Then each sample contributes equally to the average:

$$\langle A \rangle \approx \frac{1}{M} \sum_{m=1}^{M} A_m$$

No explicit weights needed. The question is how to generate samples from this distribution.

## Markov chain Monte Carlo

The solution is to construct a Markov chain — a random walk through configuration space where each step depends only on the current configuration. At each step we propose a move to a new configuration and either accept or reject it. The question is: how should we choose the acceptance probabilities to ensure we sample from our target distribution?

Consider two states. At equilibrium, the frequency of transitions from state 1 to state 2 must equal the frequency from 2 to 1 — otherwise probability would accumulate in one state. If we visit state 1 with probability π<sub>1</sub> and accept moves to state 2 with probability P(1→2), then balance requires:

$$\pi_1 \, P(1 \to 2) = \pi_2 \, P(2 \to 1)$$

Rearranging: the ratio of acceptance probabilities must equal the ratio of target probabilities:

$$\frac{P(1 \to 2)}{P(2 \to 1)} = \frac{\pi_2}{\pi_1}$$

For many states, we impose this constraint on every pair. The result is that we sample each state with probability proportional to our target distribution.

For the Boltzmann distribution, the ratio of target probabilities is:

$$\frac{\pi_2}{\pi_1} = \frac{e^{-E_2/kT}}{e^{-E_1/kT}} = e^{-\Delta E/kT}$$

This depends only on the energy difference between the two states — not on absolute energies. Since we only ever compare states pairwise, we never need to know the partition function or evaluate absolute energies.

Any acceptance rule where the ratio of forward to backward acceptance probabilities equals $\exp(-\Delta E/kT)$ will sample from the Boltzmann distribution. The Metropolis criterion is one such choice.

## The Metropolis algorithm

The Metropolis algorithm is the standard approach. The procedure is:

1. Start from some configuration with energy E<sub>1</sub>
2. Propose a move — for configurational disorder, typically swapping two atoms of different types
3. Calculate the energy E<sub>2</sub> of the new configuration
4. Accept or reject the move:
   - If ΔE ≤ 0 (energy decreased): accept
   - If ΔE > 0 (energy increased): accept with probability $\exp(-\Delta E/kT)$
5. If accepted, the new configuration becomes the current one; if rejected, stay in the old configuration
6. Repeat from step 2

The acceptance rule ensures that, after many steps, the chain visits configurations with probability proportional to $\exp(-E/kT)$.

The intuition for why the algorithm works: downhill moves are always accepted, so the chain readily finds low-energy configurations. Uphill moves are sometimes accepted — the probability $\exp(-\Delta E/kT)$ decreases exponentially with the energy cost, but is never zero. This allows the chain to escape local minima and explore configuration space. Without occasional uphill moves, we would simply find the nearest local minimum — an optimisation algorithm, not a sampling algorithm. Temperature controls exploration: at high temperature, $\exp(-\Delta E/kT)$ is close to 1 for moderate ΔE, so most moves are accepted and the system explores widely; at low temperature, only small uphill moves are accepted and the system stays near low-energy configurations.

## What you get

After an initial equilibration period, the MC chain samples configurations from the target ensemble. The expectation value of any quantity A is simply the average over sampled configurations:

$$\langle A \rangle = \frac{1}{M} \sum_{m=1}^{M} A_m$$

No Boltzmann weights appear because the sampling already accounts for them. Thermodynamic properties follow: from fluctuations in energy we get heat capacity; from the temperature dependence of order parameters we identify phase transitions. Snapshots from the MC chain represent the distribution of configurations at thermal equilibrium, and can be analysed for structural features or compared with experiment.

## What you don't get

MC does not give dynamics. The sequence of configurations is a random walk designed to sample the equilibrium distribution, not a physical trajectory through time. There is no "MC time" that corresponds to real time. Questions about rates, diffusion coefficients, or time correlation functions cannot be answered by MC.

This is the fundamental distinction: MD samples by following dynamics and gives both equilibrium and dynamic properties; MC samples configuration space directly and gives only equilibrium properties.

## Neutron connection

Neutron diffraction measures a spatial average — the scattering from many unit cells within the illuminated volume. For crystallographically disordered systems where atoms are not diffusing, this spatial average determines the measured structure.

MC models this as an average over configurations. If the system is statistically homogeneous — if any region looks like any other on average — then the spatial average equals the ensemble average over configurations.

# Cluster expansion

## The problem

Some questions in materials science concern configurational disorder on a lattice: which atoms sit on which sites? In a mixed-metal oxide, how are the cations distributed? In an alloy, do the components cluster or order? These are questions about a discrete configurational space — the lattice sites are fixed, only the occupancies vary. Monte Carlo sampling handles this naturally: propose a swap of two atoms, accept or reject based on energy change, repeat.

The challenge is evaluating the energy. A typical MC simulation involves millions of proposed moves, each requiring ΔE to be calculated. To make matters worse, atoms do not sit exactly on ideal lattice positions — they relax slightly depending on the local chemical environment. To calculate ΔE properly, each proposed configuration requires a geometry optimisation. The computational cost is not just millions of energy evaluations, but millions of geometry optimisations. With DFT, this is completely impractical. With classical potentials, it is possible but computationally demanding and slow.

Cluster expansions sidestep this entirely. The idea is to construct an effective Hamiltonian that depends only on site occupancies — not on continuous atomic positions. This Hamiltonian is parameterised by fitting to the energies of relaxed structures calculated with a more accurate method, typically DFT. Because the training data comes from fully relaxed configurations, the relaxation energy is already incorporated into the fitted coefficients. During MC sampling, no geometry optimisation is needed — evaluating the energy for any configuration is computationally trivial, enabling hundreds of MC steps per second with near-DFT accuracy.

## The idea

How is the effective Hamiltonian constructed? For a binary system (A and B atoms on fixed sites), the configuration can be represented using occupation variables: assign σ<sub>i</sub> = +1 if site i has atom A, σ<sub>i</sub> = −1 if site i has atom B. The full configuration is then specified by the set of all σ<sub>i</sub>.

The cluster expansion writes the energy as a function of these occupation variables:

$$E(\{\sigma\}) = J_0 + \sum_i J_i \sigma_i + \sum_{i<j} J_{ij} \sigma_i \sigma_j + \sum_{i<j<k} J_{ijk} \sigma_i \sigma_j \sigma_k + \ldots$$

The first term J<sub>0</sub> is a constant (the reference energy). The second sum runs over single sites — but for a stoichiometric system, the number of A and B atoms is fixed, so Σσ<sub>i</sub> is constant and this term just shifts the reference. The third sum runs over pairs of sites; J<sub>ij</sub> captures how the energy depends on whether sites i and j have the same or different atoms. Higher-order terms capture three-body, four-body, and larger cluster interactions.

## Symmetry and truncation

For a periodic crystal, symmetry constrains the expansion. All pairs related by symmetry have the same coefficient: nearest-neighbour pairs share one J value, second-nearest-neighbour pairs share another, and so on. Similarly for triplets and larger clusters. Symmetry groups the clusters into types, reducing the number of independent parameters from one per cluster to one per symmetry-distinct cluster type.

The expansion becomes:

$$E = J_0 + \sum_\alpha J_\alpha \, m_\alpha \, \langle \Pi_\alpha \rangle$$

where α labels cluster types, m<sub>α</sub> is the multiplicity (how many clusters of that type per site), and ⟨Π<sub>α</sub>⟩ is the average value of the product of occupation variables over all clusters of type α.

An infinite cluster expansion — including all cluster types — is provably exact; it can represent any function of the site occupancies. In practice, the expansion is truncated by selecting which cluster types to include. This is done by limiting both the cluster size (e.g., up to triplets or quartets) and the cluster radius (e.g., pairs only up to third-nearest neighbours).

## Fitting the expansion

The coefficients {J<sub>α</sub>} are unknown. They are determined by fitting to DFT calculations: a set of training configurations is generated, covering different arrangements of atoms on the lattice, and the DFT energy of each is calculated. The cluster expansion coefficients are then fitted to reproduce these energies. Because the energy is linear in the coefficients J<sub>α</sub>, this is a linear least-squares problem.

The training set typically includes 50–200 configurations, each requiring a DFT calculation. This is expensive upfront, but pays off when the fitted expansion enables millions of energy evaluations that would be impossible with direct DFT.

## What you get

A fitted cluster expansion evaluates E(σ) for any configuration as a sum over clusters — a fraction of a second, rather than the minutes to hours required for DFT. This makes extensive MC sampling possible: millions of steps at effectively DFT accuracy. We can map out phase diagrams, find order-disorder transition temperatures, and characterise the distribution of configurations at any temperature. Ground state searching becomes tractable — systematically enumerating configurations or using optimisation algorithms to find the lowest-energy orderings. Thermodynamic properties such as heat capacities, ordering enthalpies, and entropies follow from MC sampling.

## Limitations

Cluster expansions require that every relaxed structure can be mapped back to exactly one on-lattice configuration. The atoms in the training structures are fully relaxed — they sit at their true equilibrium positions, not ideal lattice sites — but each structure must correspond unambiguously to a particular set of site occupancies. This works well when relaxations are small, but breaks down if atoms move so far from their nominal sites that the mapping becomes ambiguous.

The expansion assumes the energy can be written as a sum over clusters. This works well for many systems but may fail when long-range interactions (beyond the clusters included) are important, or when the electronic structure changes qualitatively with ordering.

The quality depends entirely on the training data and the choice of clusters. A cluster expansion is a fit to DFT — it inherits the accuracy of the underlying DFT calculations and can only interpolate, not extrapolate. If the training set doesn't include configurations similar to what you're asking about, the expansion may give wrong answers.

# Short-range order and PDF

## Long-range order vs short-range order

Between fully ordered and maximally disordered (maximum entropy) lies an intermediate regime: the system is disordered in the sense that there is no long-range periodic pattern, but local correlations exist. This is short-range order.

Consider a binary alloy A<sub>0.5</sub>B<sub>0.5</sub> on a BCC lattice. At low temperature, it might order into a CsCl-type structure: all A atoms on one sublattice, all B on the other. This is long-range order (LRO) — correlations extend throughout the crystal, producing a periodic pattern. Bragg diffraction sees this clearly: the ordering produces superlattice reflections at positions forbidden by the disordered structure.

At high temperature, entropy wins and the alloy disorders: A and B atoms distributed over sites with no correlations between them. No long-range pattern, no superlattice reflections. This is maximum entropy — the arrangement is completely uncorrelated.

But there is an intermediate regime. Even without long-range order, local correlations may exist — short-range order (SRO). Perhaps A atoms preferentially have B neighbours, or tend to avoid other A atoms, but only over the first few coordination shells. Beyond that, correlations decay and the arrangement becomes uncorrelated. There's no periodic pattern, but there is local structure.

## What Bragg diffraction misses

Bragg diffraction is sensitive to the average, periodic structure. For a disordered alloy without LRO, the pattern shows only the underlying lattice with average scattering length. The local correlations show up as diffuse scattering between Bragg peaks — broad features that are often ignored or hard to analyse quantitatively.

Consider what diffraction tells you about site occupancies. If a site is 50% A and 50% B on average, that's what the measurement reports — regardless of whether A and B are randomly distributed or have strong local correlations. Two structures with the same average occupancy but different SRO give the same Bragg intensities.

This is a fundamental limitation: Bragg diffraction reports the spatially averaged structure. Local correlations that don't produce a periodic pattern are invisible to it.

## PDF captures local structure

Total scattering includes both Bragg and diffuse contributions. The Fourier transform of the total scattering gives the pair distribution function G(r), which measures the probability of finding atoms at separation r. Unlike Bragg diffraction, which sees only the average periodic structure, PDF is sensitive to local correlations.

For a single-element material, g(r) has peaks at the neighbour distances — first shell, second shell, and so on. For a multi-component material, partial pair distribution functions g<sub>αβ</sub>(r) can be defined: the probability of finding a β atom at distance r from an α atom. These partials encode information about local ordering. If A atoms preferentially have B neighbours, the A-B partial shows enhanced correlations at the nearest-neighbour distance compared to an uncorrelated distribution. If A atoms cluster together, the A-A partial is enhanced instead.

When short-range order is present, it shows up in the PDF: the short-range region is not well described by the model fitted to Bragg data. But while PDF can reveal that local structure differs from the long-range average, understanding what is actually happening is harder. The measured PDF sums over all partials, weighted by scattering lengths and concentrations — separating the contributions requires additional information. Even if correlations can be quantified, this does not explain them: we may learn that A prefers B neighbours, but not why. And many different local arrangements can produce similar g(r), so determining the structure from PDF alone requires additional constraints or physical insight.

## The computational approach

This is where cluster expansion and Monte Carlo methods help. CE+MC samples configurations at thermal equilibrium, weighted by their Boltzmann probabilities. This is not just generating plausible structures — it's sampling from the correct statistical distribution.

From these equilibrium configurations we can calculate ensemble-averaged properties: the probability that an A atom has a B neighbour, how correlations decay with distance, which local arrangements are favoured and which are suppressed.

Comparing with experimental PDF requires an additional step. The CE operates on-lattice, but real atoms relax from ideal positions. To generate a predicted g(r), we select representative configurations from the MC sampling, relax each using DFT (or another accurate method), and average g(r) over these relaxed structures. This ensemble-averaged g(r) can then be compared directly with experiment.

Alternatively, the relaxed structures can serve as starting models for PDF refinement. Rather than comparing computed and experimental g(r) directly, the DFT-relaxed configurations provide physically motivated structural models that experimentalists can refine against their data.

If experiment and computation agree, we have a validated atomistic model. We can then interrogate that model for insight that experiment alone cannot provide: why certain correlations exist, what drives the local ordering, how it changes with temperature or composition.

# Case study: short-range order in Li<sub>2</sub>FeSO

This section presents a case study illustrating the computational workflow developed in the preceding sections. The example — cation ordering in the antiperovskite cathode material Li<sub>2</sub>FeSO — demonstrates how cluster expansion, Monte Carlo sampling, and pair distribution function analysis combine to characterise short-range order that Bragg diffraction cannot detect. Full details are available in Coles *et al.*, *Journal of Materials Chemistry A* (2023).

## The puzzle

Li<sub>2</sub>FeSO adopts the antiperovskite structure. Sulfur occupies the 12-coordinate site, oxygen occupies the 6-coordinate octahedral site, and lithium and iron share the remaining sites in a 2:1 ratio (Fig. X). Previous diffraction studies found no superlattice reflections — no evidence of long-range cation order — leading to the assumption that Li and Fe are randomly distributed over their shared sites.

[Figure: Li<sub>2</sub>FeSO antiperovskite structure showing the shared Li/Fe sites]

But this assumption is puzzling on physical grounds. Fe²⁺ and Li⁺ have different formal charges. Simple electrostatic arguments suggest that configurations which separate the higher-charged Fe²⁺ ions should be lower in energy than configurations that cluster them together. If an energetic preference exists, why would the cation distribution be random?

The absence of long-range order does not necessarily imply the absence of short-range order. Diffraction probes the average, periodic structure; local correlations that do not produce a periodic pattern are invisible to Bragg peaks. The question is whether Li<sub>2</sub>FeSO exhibits preferential short-range cation ordering, and if so, what form it takes.

## The computational approach

To address this question, we calculated DFT energies for approximately 100 different Li/Fe configurations in supercells of Li<sub>2</sub>FeSO. These energies were used to fit a cluster expansion — a parameterised model that expresses the configurational energy as a function of site occupancies, as described in section 3.2.

With the cluster expansion in hand, Monte Carlo sampling becomes computationally tractable. We performed MC simulations in an 8&times;8&times;8 supercell at 1025 K, corresponding to the experimental synthesis temperature. The simulation generates an ensemble of configurations representative of thermal equilibrium at that temperature.

From the MC trajectory, we can extract the probability distribution of local coordination environments. Each oxygen in the structure is surrounded by six cation sites. In a material with 2:1 Li:Fe stoichiometry, the possible oxygen coordinations range from OLi<sub>6</sub> (all lithium) to OFe<sub>6</sub> (all iron), with intermediate compositions OLi₅Fe, OLi<sub>4</sub>Fe<sub>2</sub>, OLi<sub>3</sub>Fe<sub>3</sub>, OLi<sub>2</sub>Fe<sub>4</sub>, and OLiFe<sub>5</sub>.

For OLi<sub>4</sub>Fe<sub>2</sub> coordination — four lithium and two iron around the central oxygen — there are two distinct geometric arrangements. In *cis*-OLi<sub>4</sub>Fe<sub>2</sub>, the two iron atoms occupy adjacent vertices of the octahedron. In *trans*-OLi<sub>4</sub>Fe<sub>2</sub>, they occupy opposite vertices.

[Figure: Schematic of cis versus trans OLi<sub>4</sub>Fe<sub>2</sub> coordination environments]

## The result: preferential short-range order

The Monte Carlo simulations predict that the cation distribution is not random.

For a random arrangement of Li and Fe over the available sites, the probability of each oxygen coordination environment follows a binomial distribution. The most probable coordination would be OLi<sub>4</sub>Fe<sub>2</sub>, occurring in approximately 33% of oxygen environments.

The DFT-derived cluster expansion predicts a markedly different distribution. OLi<sub>4</sub>Fe<sub>2</sub> coordination accounts for 65% of oxygen environments — roughly twice the random expectation. This enhanced preference for OLi<sub>4</sub>Fe<sub>2</sub> is consistent with Pauling's second rule: coordination environments that achieve local electroneutrality are energetically favoured.

[Figure: Oxygen coordination probability distributions comparing DFT-CE model, random distribution, and point-charge model]

More unexpectedly, within the OLi<sub>4</sub>Fe<sub>2</sub> environments, 81% adopt the *cis* configuration and only 19% adopt the *trans* configuration.

This result contradicts simple electrostatic reasoning. If Li⁺ and Fe²⁺ are treated as point charges at their formal crystallographic positions, the electrostatic energy of an OLi<sub>4</sub>Fe<sub>2</sub> octahedron is minimised when the two Fe²⁺ ions occupy opposite vertices — the *trans* configuration — maximising their separation. A point-charge model predicts preferential *trans*-OLi<sub>4</sub>Fe<sub>2</sub> coordination and, consequently, long-range cation order. The DFT-derived model predicts preferential *cis*-OLi<sub>4</sub>Fe<sub>2</sub> coordination, which produces long-range disorder.

## Validation against experiment

The PDF provides a direct test of these competing structural models. From the Monte Carlo configurations, we can calculate the pair distribution function and compare it to experimental total scattering data. This particular study used X-ray total scattering, which is most sensitive to the heavier Fe and S atoms; neutron PDF on the same system would provide complementary sensitivity to the lithium correlations. The principles of the comparison — generating configurations computationally and comparing calculated g(r) to experiment — are identical regardless of the probe.

Three models were tested. The DFT-derived cluster expansion model, with its preference for *cis*-OLi<sub>4</sub>Fe<sub>2</sub> coordination, gives the best agreement with experiment (R~w~ = 14.0%). A random Li/Fe distribution gives poorer agreement (R~w~ = 16.5%) — the difference is modest but systematic, reflecting the failure to capture the enhanced OLi<sub>4</sub>Fe<sub>2</sub> coordination that the DFT model predicts. Most tellingly, a point-charge ground state with 100% *trans*-OLi<sub>4</sub>Fe<sub>2</sub> coordination gives substantially worse agreement (R~w~ = 35.2%). The structure that simple electrostatics predicts is incompatible with the experimental PDF at short range.

[Figure: Comparison of experimental and simulated PDFs for the three models]

The PDF comparison validates the DFT-derived model. The short-range order in Li<sub>2</sub>FeSO is real, and it takes the form of preferential *cis*-OLi<sub>4</sub>Fe<sub>2</sub> coordination — not the *trans* preference that point-charge electrostatics would suggest.

## The physical origin: anion polarisation

Why does DFT favour *cis* over *trans*, when simple electrostatics predicts the opposite?

The key lies in the symmetry of the anion coordination environment. In *trans*-OLi<sub>4</sub>Fe<sub>2</sub> coordination, the oxygen sits at a centre of symmetry — the distribution of cations around it is centrosymmetric. In *cis*-OLi<sub>4</sub>Fe<sub>2</sub> coordination, the oxygen sits in a non-centrosymmetric environment.

Anions in non-centrosymmetric environments experience an asymmetric electric field from the surrounding cations. This field induces electronic polarisation — the anion's electron density shifts in response. The induced dipole lowers the total electrostatic energy of the system.

Point charges cannot polarise. A model that treats ions as fixed charges at crystallographic positions misses this physics entirely. It correctly captures the preference for OLi<sub>4</sub>Fe<sub>2</sub> coordination (local electroneutrality), but incorrectly predicts *trans* over *cis* because it cannot account for the stabilisation of polar coordination environments through anion polarisation.

Analysis of the DFT calculations confirms this picture. In structures with *cis*-OLi<sub>4</sub>Fe<sub>2</sub> coordination, the oxygen anions exhibit significant electronic dipole moments. In structures with *trans*-OLi<sub>4</sub>Fe<sub>2</sub> coordination, the oxygen dipole moments are zero by symmetry. The polarisation energy tips the balance from *trans* to *cis*.

## What this example illustrates

This case study demonstrates the interplay between experiment and computation that runs through the preceding sections. Bragg diffraction correctly reported no long-range order, but could not distinguish between a truly random cation distribution and one with short-range order that lacks long-range periodicity. The combination of DFT, cluster expansion, and Monte Carlo sampling predicted a specific form of short-range order — preferential *cis*-OLi<sub>4</sub>Fe<sub>2</sub> coordination — and the PDF comparison validated this prediction against experiment. Further analysis then revealed the physical origin of this preference: anion polarisation in non-centrosymmetric coordination environments, physics that the experiment could not directly access but that computation reveals.

The relationship was bidirectional throughout. The experimental observation of "no long-range order" prompted the computational investigation. The computational result was validated against experimental PDF data. And the physical insight emerged from analysing why the DFT results differed from simple electrostatic expectations.

For this material, "disordered" does not mean "random." The distinction matters: short-range cation order in cathode materials affects lithium transport, redox behaviour, and electrochemical performance. Characterising that order required the combination of total scattering and computation that this case study illustrates.